{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNgGaLCiYer4oJjW3lRYrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renshui-MC/Physics-based-deep-learning/blob/main/Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based Deep Learning**\n",
        "\n",
        "[Physics-based Deep learning (PBML)](https://physicsbaseddeeplearning.org/overview.html) denotes combinations of **physical modelling and numerical simulations**, .e.g, CFD simulations, with methods based on **airtifical neural networks**. Pysicals based deep learning represents a quickly growing and exiciting field of research. \n",
        "\n",
        "Although many success studies have shown that the deep learning (DL) methods have the potential to replace the tradietional models that are carefully crafted from *first principles*, e.g. NN-based surrogate models that can achieve accuracies required for real-world applications, to provide *correct answers.* While it is **crutial** for the next generation of simulation to combine ML with *classical numerical* methods, i.e., integrating the understanding of physics into the learning algorithms. The main objectives are:\n",
        "\n",
        "+ know how to use deep learning to solve partial differential equations (PDE) problmes\n",
        "+ combine them with **existing knowledge** of physics\n",
        "\n",
        "##Categorization\n",
        "\n",
        "Physics-based DL approaches either aim at *forward simulations (predicting states)* or *inverse problems (parameterizing a physical system from observations)*. Note that a physical system is composed of a set of PDEs. The PBML techniques can be roughly classified into three categories:\n",
        "\n",
        "1. *Supervised*: The data are obtained from a physical system (real or simulated)\n",
        "2. *Loss-terms*: Learning process iteratively evaluates the loss based on gradients from PDE-based formulation. It is called Physics-based training.\n",
        "3.*Interleaved*: numerical simulation is interleaved and combined withan output from a deep neural network.\n",
        "\n",
        "##Differential physics\n",
        "\n",
        "#**Models and Equations**\n",
        "The goal of DL is to approximate an unknown function:\n",
        "\n",
        "\\begin{align}\n",
        "    f^{(*)}(x) = y^*. \\tag{1}\\label{eq:1} \n",
        "\\end{align}\n",
        "\n",
        "In Eqn. \\ref{eq:1}, $y^{*}$ represents the **ground truth** solutions. $f^{*}(x)$ is approximated from an NN method. NN represents $f^{*}(x)$ with $f(x;\\theta)$ which is the **output** of NN. Typically, $f^{*}(x)$ can be determined by evaluating a **variant of loss function (error or objective function)**: $L\\left(f(x;\\theta), y^*\\right)$. Therefore, our purpose is to minimize $f(x;\\theta)$ such that:\n",
        "\n",
        "\\begin{align}\n",
        "  \\arg \\min _\\theta\\left|f(x ; \\theta)-y^*\\right|^2. \\tag{2}\\label{Eq:2}\n",
        "\\end{align}\n",
        "\n",
        "Equation \\ref{Eq:2} shows the simplest form of the **loss function**. Typically, the loss function is trained with a **stochastic gradient descent (SGD)** method, i.e., computing the *L* with respect to the weights ($\\theta$) or $\\partial L/\\partial \\theta$. \n",
        "\n",
        "**Three categories of data sets** need to be distinguished when training:\n",
        "\n",
        "1. **training data set** drawn from some distribution\n",
        "2. **validation** set from the same distribution for the training set, but different data\n",
        "3. **test data sets** with some **different distribution** than the training one\n",
        "\n",
        "##PDEs in physical models\n",
        " PDEs or transport equations are used to describe the physical systems. It is crutial to know how to represent PDEs in ML:\n",
        "\n",
        " + **continuous** PDEs denoted $P^{*}$ \n",
        " + $P^{*}$ solution is in **a spatial domain** $\\Omega \\subset \\mathbb{R}^d$ in $ d \\in 1,2,3$ dimensions\n",
        " + finite time interval $t \\in \\mathbb{R}^{+}$\n",
        " + solution fields are either **vector fields (u)** or **scalar fields (p)**: $\\mathbf{v}=\\left(v_x, v_y, v_z\\right)^T$ for $d = 3$ and $p \\in \\Omega$\n",
        " + We assume $P^{*}$ is continous such that its **first and second** derivatives exist.\n",
        " + numerical method to solve $P^{*}$ needs discretization, and hence, **discretization errors** will exist\n",
        " + The general form of **discretized $P^{*}$** can be written as: $\\mathbf{u}(\\mathbf{x}, t+\\Delta t)=\\mathcal{P}\\left(\\mathbf{u}_x, \\mathbf{u}_{x x}, \\ldots \\mathbf{u}_{x x \\ldots x}\\right)$ where $u_x$ denotes spatial direvatives $\\partial \\mathbf{u}(\\mathbf{x}, t) / \\partial \\mathbf{x}$\n",
        "\n",
        " ##Some example PDEs\n",
        " 1. **Burgers**: $\\frac{\\partial u}{\\partial t}+u \\nabla u=\\nu \\nabla \\cdot \\nabla u$ only consists of diffusion and advection terms. \n",
        " 2. **Navier-stokes Equations**\n",
        "\n",
        " It should be noted that **forward** simulation solves these PDEs by starting from **inital and boundary conditions** of these discretized version of the model equations.    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nYRRAVCDj7dS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6gkaaCwj6R4"
      },
      "outputs": [],
      "source": []
    }
  ]
}